{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71102777",
   "metadata": {},
   "source": [
    "### OCI Data Science - Useful Tips\n",
    "<details>\n",
    "<summary><font size=\"2\">Check for Public Internet Access</font></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "response = requests.get(\"https://oracle.com\")\n",
    "assert response.status_code==200, \"Internet connection failed\"\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Helpful Documentation </font></summary>\n",
    "<ul><li><a href=\"https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm\">Data Science Service Documentation</a></li>\n",
    "<li><a href=\"https://docs.cloud.oracle.com/iaas/tools/ads-sdk/latest/index.html\">ADS documentation</a></li>\n",
    "</ul>\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Typical Cell Imports and Settings for ADS</font></summary>\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "import ads\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.automl.provider import OracleAutoMLProvider\n",
    "from ads.automl.driver import AutoML\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from ads.common.data import ADSData\n",
    "from ads.explanations.explainer import ADSExplainer\n",
    "from ads.explanations.mlx_global_explainer import MLXGlobalExplainer\n",
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Useful Environment Variables</font></summary>\n",
    "\n",
    "```python\n",
    "import os\n",
    "print(os.environ[\"NB_SESSION_COMPARTMENT_OCID\"])\n",
    "print(os.environ[\"PROJECT_OCID\"])\n",
    "print(os.environ[\"USER_OCID\"])\n",
    "print(os.environ[\"TENANCY_OCID\"])\n",
    "print(os.environ[\"NB_REGION\"])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6542733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE OF MONITORING CODE SENDING ERROR TO SPLUNK\n",
    "from utils.code_monitoring import *\n",
    "\n",
    "configure_logging()\n",
    "\n",
    "try:\n",
    "    # Your main code here\n",
    "    ...\n",
    "\n",
    "except Exception as e:\n",
    "    error_message = f\"An error occurred: {str(e)}\"\n",
    "    send_to_splunk(error_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6cf28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# EXAMPLE READ/WRITE DELTA LAKE\n",
    "from utils.IO import DeltaLakeUtils\n",
    "\n",
    "# Example usage of the DeltaLakeUtils class\n",
    "DELTA_TABLE_PATH = \"/path/to/delta_table\"  # Update with your Delta Lake path\n",
    "\n",
    "utils = DeltaLakeUtils(DELTA_TABLE_PATH)\n",
    "\n",
    "# Reading data from a Delta Lake table\n",
    "data = utils.read_table_as_dataframe()\n",
    "if data is not None:\n",
    "    # Perform your queries or manipulations on the DataFrame\n",
    "    print(\"Data read from Delta Lake table:\")\n",
    "    data.show()\n",
    "\n",
    "# Example Spark SQL query\n",
    "query = \"SELECT * FROM delta.`{}` WHERE column_name = 'value'\".format(DELTA_TABLE_PATH)\n",
    "result = utils.run_sql_query(query)\n",
    "if result is not None:\n",
    "    print(\"Query result:\")\n",
    "    result.show()\n",
    "\n",
    "# Create a new DataFrame (example)\n",
    "new_data = utils.spark.createDataFrame([\n",
    "    (101, 'A'),\n",
    "    (102, 'B'),\n",
    "    (103, 'C')\n",
    "], [\"ID\", \"Value\"])\n",
    "\n",
    "# Writing a DataFrame to a Delta Lake table\n",
    "utils.write_dataframe_to_table(new_data)\n",
    "\n",
    "# Close the Spark session\n",
    "utils.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a538dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES\n",
    "import pandas as pd\n",
    "import utils.IO as IO\n",
    "import ads\n",
    "\n",
    "# LOAD DATA\n",
    "ads.set_auth(auth='resource_principal')\n",
    "\n",
    "# if you want to load more tables, use the function multiple times with different parameters and variable name to store dataframe\n",
    "df = IO.load_file_from_bucket(bucket_name='...',\n",
    "                              namespace='...',\n",
    "                              filename='...')\n",
    "\n",
    "# YOUR CODE\n",
    "...\n",
    "\n",
    "# LOAD MODEL\n",
    "...\n",
    "\n",
    "# WRITE DATA\n",
    "IO.write_file_in_bucket(dataset_to_write=df,\n",
    "                        bucket_name='...',\n",
    "                        namespace='...',\n",
    "                        filename='...')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bonus_sensitivity_prod_envv1_0]",
   "language": "python",
   "name": "conda-env-bonus_sensitivity_prod_envv1_0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
